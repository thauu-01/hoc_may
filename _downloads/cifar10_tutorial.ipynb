{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hQwvm_96TuXC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK8fI3eQTuXF"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1w_BeHjDTuXH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NneNcZa8TuXH"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bTqIayrBTuXH"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_e193M7TuXI"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "5glVvVReTuXI",
        "outputId": "5963f3fe-a1dd-429b-ac97-2fc145b6bfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " bird truck truck  ship\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm4LQ1yUTuXI"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MeZtfNnTuXJ",
        "outputId": "cfdb20fe-ddd2-4adc-b8d1-5f506c292566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]           2,432\n",
            "            Conv2d-2           [-1, 32, 32, 32]           9,248\n",
            "            Conv2d-3           [-1, 48, 32, 32]          38,448\n",
            "            Conv2d-4           [-1, 48, 32, 32]          20,784\n",
            "            Conv2d-5           [-1, 64, 32, 32]          76,864\n",
            "            Conv2d-6           [-1, 64, 32, 32]          36,928\n",
            "            Conv2d-7           [-1, 80, 16, 16]         128,080\n",
            "            Conv2d-8           [-1, 48, 32, 32]          20,784\n",
            "            Conv2d-9           [-1, 48, 32, 32]          57,648\n",
            "           Conv2d-10           [-1, 80, 16, 16]          34,640\n",
            "           Conv2d-11          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-12          [-1, 160, 16, 16]         640,160\n",
            "           Conv2d-13          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-14          [-1, 160, 16, 16]         640,160\n",
            "           Conv2d-15          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-16          [-1, 192, 16, 16]         768,192\n",
            "           Conv2d-17          [-1, 192, 16, 16]         331,968\n",
            "           Conv2d-18            [-1, 224, 8, 8]       1,075,424\n",
            "           Conv2d-19            [-1, 320, 8, 8]          72,000\n",
            "           Conv2d-20            [-1, 160, 8, 8]         322,720\n",
            "           Conv2d-21            [-1, 160, 8, 8]         640,160\n",
            "           Conv2d-22            [-1, 128, 8, 8]         716,928\n",
            "           Conv2d-23            [-1, 160, 8, 8]         184,480\n",
            "           Conv2d-24            [-1, 320, 8, 8]         921,920\n",
            "           Conv2d-25            [-1, 320, 8, 8]       2,560,320\n",
            "           Conv2d-26            [-1, 320, 8, 8]         921,920\n",
            "           Conv2d-27            [-1, 320, 8, 8]       2,560,320\n",
            "           Conv2d-28            [-1, 320, 8, 8]         921,920\n",
            "        MaxPool2d-29            [-1, 320, 4, 4]               0\n",
            "        MaxPool2d-30            [-1, 320, 2, 2]               0\n",
            "        MaxPool2d-31            [-1, 320, 1, 1]               0\n",
            "           Linear-32                  [-1, 512]         164,352\n",
            "           Linear-33                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,565,610\n",
            "Trainable params: 14,565,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.02\n",
            "Params size (MB): 55.56\n",
            "Estimated Total Size (MB): 62.60\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Khối 1: Các lớp ban đầu (2 conv5x5, 2 conv3x3)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)       # 32x32x32\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)      # 32x32x32\n",
        "        self.conv3 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2)      # 32x32x48\n",
        "        self.conv4 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1)      # 32x32x48\n",
        "\n",
        "        # Khối 2: Phân nhánh (2 conv5x5, 2 conv3x3 mỗi nhánh)\n",
        "        # Nhánh A\n",
        "        self.conv5a = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)     # 32x32x64\n",
        "        self.conv6a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)     # 32x32x64\n",
        "        self.conv7a = nn.Conv2d(64, 80, kernel_size=5, stride=2, padding=2)     # 16x16x80\n",
        "\n",
        "        # Nhánh B\n",
        "        self.conv5b = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1)     # 32x32x48\n",
        "        self.conv6b = nn.Conv2d(48, 48, kernel_size=5, stride=1, padding=2)     # 32x32x48\n",
        "        self.conv7b = nn.Conv2d(48, 80, kernel_size=3, stride=2, padding=1)     # 16x16x80\n",
        "\n",
        "        # Sau nối: 80+80=160 kênh (2 conv5x5, 2 conv3x3)\n",
        "        self.conv8 = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)    # 16x16x160\n",
        "        self.conv9 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)    # 16x16x160\n",
        "        self.conv10 = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)   # 16x16x160\n",
        "        self.conv11 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)   # 16x16x160\n",
        "\n",
        "        # Đường residual 1: tạo tensor 16x16x160 để cộng\n",
        "        self.res_conv1 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)  # 16x16x160\n",
        "\n",
        "        # Khối 3: Đặc trưng sâu hơn (2 conv5x5, 1 conv3x3)\n",
        "        self.conv12 = nn.Conv2d(160, 192, kernel_size=5, stride=1, padding=2)   # 16x16x192\n",
        "        self.conv13 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)   # 16x16x192\n",
        "        self.conv14 = nn.Conv2d(192, 224, kernel_size=5, stride=2, padding=2)   # 8x8x224\n",
        "\n",
        "        # Khối 4: Phân nhánh 2 (2 conv5x5, 2 conv3x3 mỗi nhánh)\n",
        "        # Nhánh C\n",
        "        self.conv15c = nn.Conv2d(224, 160, kernel_size=3, stride=1, padding=1)  # 8x8x160\n",
        "        self.conv16c = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)  # 8x8x160\n",
        "\n",
        "        # Nhánh D\n",
        "        self.conv15d = nn.Conv2d(224, 128, kernel_size=5, stride=1, padding=2)  # 8x8x128\n",
        "        self.conv16d = nn.Conv2d(128, 160, kernel_size=3, stride=1, padding=1)  # 8x8x160\n",
        "\n",
        "        # Sau nối 2: 160+160=320 kênh (2 conv5x5, 2 conv3x3)\n",
        "        self.conv17 = nn.Conv2d(320, 320, kernel_size=5, stride=1, padding=2)   # 8x8x320\n",
        "        self.conv18 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)   # 8x8x320\n",
        "        self.conv19 = nn.Conv2d(320, 320, kernel_size=5, stride=1, padding=2)   # 8x8x320\n",
        "        self.conv20 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)   # 8x8x320\n",
        "\n",
        "        # Đường residual 2: tạo tensor 8x8x320 để cộng\n",
        "        self.res_conv2 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)  # 8x8x320\n",
        "\n",
        "        # Đường residual 3: tạo tensor 8x8x320 để cộng (từ khối 3)\n",
        "        self.res_proj3 = nn.Conv2d(224, 320, kernel_size=1, stride=1)  # 8x8x224 -> 8x8x320\n",
        "\n",
        "        # Các lớp MaxPooling\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(2)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(3)\n",
        "\n",
        "        # Các lớp fully connected\n",
        "        self.fc1 = nn.Linear(320 * 1 * 1, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Khối 1: 32x32x3 -> 32x32x48 (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))  # 32x32x48\n",
        "\n",
        "        # Khối 2: Phân nhánh (6 conv: 3 x 5x5, 3 x 3x3)\n",
        "        # Nhánh A: 32x32x48 -> 16x16x80\n",
        "        branch_a = F.relu(self.conv5a(x))\n",
        "        branch_a = F.relu(self.conv6a(branch_a))\n",
        "        branch_a = F.relu(self.conv7a(branch_a))\n",
        "\n",
        "        # Nhánh B: 32x32x48 -> 16x16x80\n",
        "        branch_b = F.relu(self.conv5b(x))\n",
        "        branch_b = F.relu(self.conv6b(branch_b))\n",
        "        branch_b = F.relu(self.conv7b(branch_b))\n",
        "\n",
        "        # Nối 1: torch.cat (80+80=160)\n",
        "        x = torch.cat((branch_a, branch_b), dim=1)  # 16x16x160\n",
        "\n",
        "        # Lưu cho residual 1\n",
        "        residual1 = self.res_conv1(x)  # 16x16x160\n",
        "\n",
        "        # Xử lý sau nối (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv8(x))   # 16x16x160\n",
        "        x = F.relu(self.conv9(x))   # 16x16x160\n",
        "        x = F.relu(self.conv10(x))  # 16x16x160\n",
        "        x = F.relu(self.conv11(x))  # 16x16x160\n",
        "\n",
        "        # Cộng 1: 16x16x160 + 16x16x160 = 16x16x160\n",
        "        x = x + residual1  # 16x16x160\n",
        "\n",
        "        # Khối 3: 16x16x160 -> 8x8x224 (3 conv: 2 x 5x5, 1 x 3x3)\n",
        "        x = F.relu(self.conv12(x))  # 16x16x192\n",
        "        x = F.relu(self.conv13(x))  # 16x16x192\n",
        "        x = F.relu(self.conv14(x))  # 8x8x224\n",
        "\n",
        "        # Lưu cho residual 3\n",
        "        residual3 = self.res_proj3(x)  # 8x8x320\n",
        "\n",
        "        # Khối 4: Phân nhánh 2 (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        # Nhánh C: 8x8x224 -> 8x8x160\n",
        "        branch_c = F.relu(self.conv15c(x))\n",
        "        branch_c = F.relu(self.conv16c(branch_c))\n",
        "\n",
        "        # Nhánh D: 8x8x224 -> 8x8x160\n",
        "        branch_d = F.relu(self.conv15d(x))\n",
        "        branch_d = F.relu(self.conv16d(branch_d))\n",
        "\n",
        "        # Nối 2: torch.cat (160+160=320)\n",
        "        x = torch.cat((branch_c, branch_d), dim=1)  # 8x8x320\n",
        "\n",
        "        # Lưu cho residual 2\n",
        "        residual2 = self.res_conv2(x)  # 8x8x320\n",
        "\n",
        "        # Các conv cuối (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv17(x))  # 8x8x320\n",
        "        x = F.relu(self.conv18(x))  # 8x8x320\n",
        "        x = F.relu(self.conv19(x))  # 8x8x320\n",
        "        x = F.relu(self.conv20(x))  # 8x8x320\n",
        "\n",
        "        # Cộng 2: 8x8x320 + 8x8x320 = 8x8x320\n",
        "        x = x + residual2  # 8x8x320\n",
        "\n",
        "        # Cộng 3: 8x8x320 + 8x8x320 = 8x8x320\n",
        "        x = x + residual3  # 8x8x320\n",
        "\n",
        "        # Các lớp MaxPooling\n",
        "        x = self.pool1(x)  # 4x4x320 - MaxPool(1)\n",
        "        x = self.pool2(x)  # 2x2x320 - MaxPool(2)\n",
        "        x = self.pool3(x)  # 1x1x320 - MaxPool(3)\n",
        "\n",
        "        # Flatten và các lớp FC\n",
        "        x = x.view(-1, 320 * 1 * 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ==========================\n",
        "# Cách dùng\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net().to(device)\n",
        "\n",
        "# In cấu trúc mạng\n",
        "from torchsummary import summary\n",
        "summary(net, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij9NAA8yTuXJ"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SWXnQzsVTuXJ"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJdU11DiTuXJ"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WVjhjGvTuXJ",
        "outputId": "3c3eed13-8b92-48bf-c731-e78c60d3ea1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.303\n",
            "[1,  4000] loss: 2.304\n",
            "[1,  6000] loss: 2.304\n",
            "[1,  8000] loss: 2.304\n",
            "[1, 10000] loss: 2.304\n",
            "[1, 12000] loss: 2.304\n",
            "[2,  2000] loss: 2.303\n",
            "[2,  4000] loss: 2.304\n",
            "[2,  6000] loss: 2.303\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(12):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %https://mail.google.com/mail/u/1/#inbox\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePdh5abjTuXJ"
      },
      "source": [
        "5. Test the network on the test data\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQClVx3iTuXK"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vyCBRkGTuXK"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H9MUUnWTuXK"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5vNQylpTuXK"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCgoyW0hTuXK"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7l-E71bTuXK"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoDFxAo7TuXK"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkW3unxqTuXK"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CNTlOrVTuXK"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6SMcaMsTuXK"
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "How do we run these neural networks on the GPU?\n",
        "\n",
        "Training on GPU\n",
        "----------------\n",
        "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
        "net onto the GPU.\n",
        "\n",
        "Let's first define our device as the first visible cuda device if we have\n",
        "CUDA available:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UyYR-n2TuXK",
        "outputId": "18fea937-1470-47bd-a677-0c3e9ac4b41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p4L6SL9TuXL"
      },
      "source": [
        "The rest of this section assumes that `device` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is realllly small.\n",
        "\n",
        "**Exercise:** Try increasing the width of your network (argument 2 of\n",
        "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
        "they need to be the same number), see what kind of speedup you get.\n",
        "\n",
        "**Goals achieved**:\n",
        "\n",
        "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
        "- Train a small neural network to classify images\n",
        "\n",
        "Training on multiple GPUs\n",
        "-------------------------\n",
        "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
        "please check out :doc:`data_parallel_tutorial`.\n",
        "\n",
        "Where do I go next?\n",
        "-------------------\n",
        "\n",
        "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
        "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
        "-  `Train a face generator using Generative Adversarial Networks`_\n",
        "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
        "-  `More examples`_\n",
        "-  `More tutorials`_\n",
        "-  `Discuss PyTorch on the Forums`_\n",
        "-  `Chat with other users on Slack`_\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "history_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}