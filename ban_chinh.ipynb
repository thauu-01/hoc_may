{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thauu-01/hoc_may/blob/main/ban_chinh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hQwvm_96TuXC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK8fI3eQTuXF"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1w_BeHjDTuXH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NneNcZa8TuXH"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTqIayrBTuXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53637bd8-4b32-42fe-efd3-708cf9b2a543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 60.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_e193M7TuXI"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "5glVvVReTuXI",
        "outputId": "7f2e7086-735d-404c-8fd4-621cccfa9a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  car plane   dog  ship\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm4LQ1yUTuXI"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MeZtfNnTuXJ",
        "outputId": "16dc3ca0-9c26-4cb4-aa6b-edbd648b4549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]           2,432\n",
            "            Conv2d-2           [-1, 32, 32, 32]           9,248\n",
            "            Conv2d-3           [-1, 48, 32, 32]          38,448\n",
            "            Conv2d-4           [-1, 48, 32, 32]          20,784\n",
            "            Conv2d-5           [-1, 64, 32, 32]          76,864\n",
            "            Conv2d-6           [-1, 64, 32, 32]          36,928\n",
            "            Conv2d-7           [-1, 80, 16, 16]         128,080\n",
            "            Conv2d-8           [-1, 48, 32, 32]          20,784\n",
            "            Conv2d-9           [-1, 48, 32, 32]          57,648\n",
            "           Conv2d-10           [-1, 80, 16, 16]          34,640\n",
            "           Conv2d-11          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-12          [-1, 160, 16, 16]         640,160\n",
            "           Conv2d-13          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-14          [-1, 160, 16, 16]         640,160\n",
            "           Conv2d-15          [-1, 160, 16, 16]         230,560\n",
            "           Conv2d-16          [-1, 192, 16, 16]         768,192\n",
            "           Conv2d-17          [-1, 192, 16, 16]         331,968\n",
            "           Conv2d-18            [-1, 224, 8, 8]       1,075,424\n",
            "           Conv2d-19            [-1, 320, 8, 8]          72,000\n",
            "           Conv2d-20            [-1, 160, 8, 8]         322,720\n",
            "           Conv2d-21            [-1, 160, 8, 8]         640,160\n",
            "           Conv2d-22            [-1, 128, 8, 8]         716,928\n",
            "           Conv2d-23            [-1, 160, 8, 8]         184,480\n",
            "           Conv2d-24            [-1, 320, 8, 8]         921,920\n",
            "           Conv2d-25            [-1, 320, 8, 8]       2,560,320\n",
            "           Conv2d-26            [-1, 320, 8, 8]         921,920\n",
            "           Conv2d-27            [-1, 320, 8, 8]       2,560,320\n",
            "           Conv2d-28            [-1, 320, 8, 8]         921,920\n",
            "        MaxPool2d-29            [-1, 320, 4, 4]               0\n",
            "        MaxPool2d-30            [-1, 320, 2, 2]               0\n",
            "        MaxPool2d-31            [-1, 320, 1, 1]               0\n",
            "           Linear-32                  [-1, 512]         164,352\n",
            "           Linear-33                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,565,610\n",
            "Trainable params: 14,565,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.02\n",
            "Params size (MB): 55.56\n",
            "Estimated Total Size (MB): 62.60\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Khối 1: Các lớp ban đầu (2 conv5x5, 2 conv3x3)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)       # 32x32x32\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)      # 32x32x32\n",
        "        self.conv3 = nn.Conv2d(32, 48, kernel_size=5, stride=1, padding=2)      # 32x32x48\n",
        "        self.conv4 = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1)      # 32x32x48\n",
        "\n",
        "        # Khối 2: Phân nhánh (2 conv5x5, 2 conv3x3 mỗi nhánh)\n",
        "        # Nhánh A\n",
        "        self.conv5a = nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2)     # 32x32x64\n",
        "        self.conv6a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)     # 32x32x64\n",
        "        self.conv7a = nn.Conv2d(64, 80, kernel_size=5, stride=2, padding=2)     # 16x16x80\n",
        "\n",
        "        # Nhánh B\n",
        "        self.conv5b = nn.Conv2d(48, 48, kernel_size=3, stride=1, padding=1)     # 32x32x48\n",
        "        self.conv6b = nn.Conv2d(48, 48, kernel_size=5, stride=1, padding=2)     # 32x32x48\n",
        "        self.conv7b = nn.Conv2d(48, 80, kernel_size=3, stride=2, padding=1)     # 16x16x80\n",
        "\n",
        "        # Sau nối: 80+80=160 kênh (2 conv5x5, 2 conv3x3)\n",
        "        self.conv8 = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)    # 16x16x160\n",
        "        self.conv9 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)    # 16x16x160\n",
        "        self.conv10 = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)   # 16x16x160\n",
        "        self.conv11 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)   # 16x16x160\n",
        "\n",
        "        # Đường residual 1: tạo tensor 16x16x160 để cộng\n",
        "        self.conv12 = nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1)  # 16x16x160\n",
        "\n",
        "        # Khối 3: Đặc trưng sâu hơn (2 conv5x5, 1 conv3x3)\n",
        "        self.conv13 = nn.Conv2d(160, 192, kernel_size=5, stride=1, padding=2)   # 16x16x192\n",
        "        self.conv14 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)   # 16x16x192\n",
        "        self.conv15 = nn.Conv2d(192, 224, kernel_size=5, stride=2, padding=2)   # 8x8x224\n",
        "\n",
        "        # Khối 4: Phân nhánh 2 (2 conv5x5, 2 conv3x3 mỗi nhánh)\n",
        "        # Nhánh C\n",
        "        self.conv16c = nn.Conv2d(224, 160, kernel_size=3, stride=1, padding=1)  # 8x8x160\n",
        "        self.conv17c = nn.Conv2d(160, 160, kernel_size=5, stride=1, padding=2)  # 8x8x160\n",
        "\n",
        "        # Nhánh D\n",
        "        self.conv16d = nn.Conv2d(224, 128, kernel_size=5, stride=1, padding=2)  # 8x8x128\n",
        "        self.conv17d = nn.Conv2d(128, 160, kernel_size=3, stride=1, padding=1)  # 8x8x160\n",
        "\n",
        "        # Sau nối 2: 160+160=320 kênh (2 conv5x5, 2 conv3x3)\n",
        "        self.conv18 = nn.Conv2d(320, 320, kernel_size=5, stride=1, padding=2)   # 8x8x320\n",
        "        self.conv19 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)   # 8x8x320\n",
        "        self.conv20 = nn.Conv2d(320, 320, kernel_size=5, stride=1, padding=2)   # 8x8x320\n",
        "        self.conv21 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)   # 8x8x320\n",
        "\n",
        "        # Đường residual 2: tạo tensor 8x8x320 để cộng\n",
        "        self.conv22 = nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1)  # 8x8x320\n",
        "\n",
        "        # Đường residual 3: tạo tensor 8x8x320 để cộng (từ khối 3)\n",
        "        self.conv23 = nn.Conv2d(224, 320, kernel_size=1, stride=1)  # 8x8x224 -> 8x8x320\n",
        "\n",
        "        # Các lớp MaxPooling\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(2)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool(3)\n",
        "\n",
        "        # Các lớp fully connected\n",
        "        self.fc1 = nn.Linear(320 * 1 * 1, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Khối 1: 32x32x3 -> 32x32x48 (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))  # 32x32x48\n",
        "\n",
        "        # Khối 2: Phân nhánh (6 conv: 3 x 5x5, 3 x 3x3)\n",
        "        # Nhánh A: 32x32x48 -> 16x16x80\n",
        "        branch_a = F.relu(self.conv5a(x))\n",
        "        branch_a = F.relu(self.conv6a(branch_a))\n",
        "        branch_a = F.relu(self.conv7a(branch_a))\n",
        "\n",
        "        # Nhánh B: 32x32x48 -> 16x16x80\n",
        "        branch_b = F.relu(self.conv5b(x))\n",
        "        branch_b = F.relu(self.conv6b(branch_b))\n",
        "        branch_b = F.relu(self.conv7b(branch_b))\n",
        "\n",
        "        # Nối 1: torch.cat (80+80=160)\n",
        "        x = torch.cat((branch_a, branch_b), dim=1)  # 16x16x160\n",
        "\n",
        "        # Lưu cho residual 1\n",
        "        residual1 = self.conv12(x)  # 16x16x160\n",
        "\n",
        "        # Xử lý sau nối (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv8(x))   # 16x16x160\n",
        "        x = F.relu(self.conv9(x))   # 16x16x160\n",
        "        x = F.relu(self.conv10(x))  # 16x16x160\n",
        "        x = F.relu(self.conv11(x))  # 16x16x160\n",
        "\n",
        "        # Cộng 1: 16x16x160 + 16x16x160 = 16x16x160\n",
        "        x = x + residual1  # 16x16x160\n",
        "\n",
        "        # Khối 3: 16x16x160 -> 8x8x224 (3 conv: 2 x 5x5, 1 x 3x3)\n",
        "        x = F.relu(self.conv13(x))  # 16x16x192\n",
        "        x = F.relu(self.conv14(x))  # 16x16x192\n",
        "        x = F.relu(self.conv15(x))  # 8x8x224\n",
        "\n",
        "        # Lưu cho residual 3\n",
        "        residual3 = self.conv23(x)  # 8x8x320\n",
        "\n",
        "        # Khối 4: Phân nhánh 2 (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        # Nhánh C: 8x8x224 -> 8x8x160\n",
        "        branch_c = F.relu(self.conv16c(x))\n",
        "        branch_c = F.relu(self.conv17c(branch_c))\n",
        "\n",
        "        # Nhánh D: 8x8x224 -> 8x8x160\n",
        "        branch_d = F.relu(self.conv16d(x))\n",
        "        branch_d = F.relu(self.conv17d(branch_d))\n",
        "\n",
        "        # Nối 2: torch.cat (160+160=320)\n",
        "        x = torch.cat((branch_c, branch_d), dim=1)  # 8x8x320\n",
        "\n",
        "        # Lưu cho residual 2\n",
        "        residual2 = self.conv22(x)  # 8x8x320\n",
        "\n",
        "        # Các conv cuối (4 conv: 2 x 5x5, 2 x 3x3)\n",
        "        x = F.relu(self.conv18(x))  # 8x8x320\n",
        "        x = F.relu(self.conv19(x))  # 8x8x320\n",
        "        x = F.relu(self.conv20(x))  # 8x8x320\n",
        "        x = F.relu(self.conv21(x))  # 8x8x320\n",
        "\n",
        "        # Cộng 2: 8x8x320 + 8x8x320 = 8x8x320\n",
        "        x = x + residual2  # 8x8x320\n",
        "\n",
        "        # Cộng 3: 8x8x320 + 8x8x320 = 8x8x320\n",
        "        x = x + residual3  # 8x8x320\n",
        "\n",
        "        # Các lớp MaxPooling\n",
        "        x = self.pool1(x)  # 4x4x320 - MaxPool(1)\n",
        "        x = self.pool2(x)  # 2x2x320 - MaxPool(2)\n",
        "        x = self.pool3(x)  # 1x1x320 - MaxPool(3)\n",
        "\n",
        "        # Flatten và các lớp FC\n",
        "        x = x.view(-1, 320 * 1 * 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ==========================\n",
        "# Cách dùng\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net().to(device)\n",
        "\n",
        "# In cấu trúc mạng\n",
        "from torchsummary import summary\n",
        "summary(net, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij9NAA8yTuXJ"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWXnQzsVTuXJ"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJdU11DiTuXJ"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WVjhjGvTuXJ",
        "outputId": "4b87396a-d142-4cea-e27a-2d2e63f1c39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.304\n",
            "[1,  4000] loss: 2.304\n",
            "[1,  6000] loss: 2.304\n",
            "[1,  8000] loss: 2.304\n",
            "[1, 10000] loss: 2.304\n",
            "[1, 12000] loss: 2.303\n",
            "[2,  2000] loss: 2.303\n",
            "[2,  4000] loss: 2.303\n",
            "[2,  6000] loss: 2.304\n",
            "[2,  8000] loss: 2.304\n",
            "[2, 10000] loss: 2.303\n",
            "[2, 12000] loss: 2.303\n",
            "[3,  2000] loss: 2.303\n",
            "[3,  4000] loss: 2.304\n",
            "[3,  6000] loss: 2.303\n",
            "[3,  8000] loss: 2.303\n",
            "[3, 10000] loss: 2.303\n",
            "[3, 12000] loss: 2.304\n",
            "[4,  2000] loss: 2.303\n",
            "[4,  4000] loss: 2.303\n",
            "[4,  6000] loss: 2.303\n",
            "[4,  8000] loss: 2.304\n",
            "[4, 10000] loss: 2.303\n",
            "[4, 12000] loss: 2.303\n",
            "[5,  2000] loss: 2.304\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(12):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePdh5abjTuXJ"
      },
      "source": [
        "5. Test the network on the test data\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQClVx3iTuXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0c09e497-84aa-4551-bfc2-428e6aa8dcd8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'testloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-793218218.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testloader' is not defined"
          ]
        }
      ],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vyCBRkGTuXK"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H9MUUnWTuXK"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5vNQylpTuXK"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCgoyW0hTuXK"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7l-E71bTuXK"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoDFxAo7TuXK"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkW3unxqTuXK"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CNTlOrVTuXK"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6SMcaMsTuXK"
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "How do we run these neural networks on the GPU?\n",
        "\n",
        "Training on GPU\n",
        "----------------\n",
        "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
        "net onto the GPU.\n",
        "\n",
        "Let's first define our device as the first visible cuda device if we have\n",
        "CUDA available:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3UyYR-n2TuXK",
        "outputId": "cf04795d-9eae-49ec-edaf-03c84eb286df"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3586096779.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assume that we are on a CUDA machine, then this should print a CUDA device:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p4L6SL9TuXL"
      },
      "source": [
        "The rest of this section assumes that `device` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is realllly small.\n",
        "\n",
        "**Exercise:** Try increasing the width of your network (argument 2 of\n",
        "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
        "they need to be the same number), see what kind of speedup you get.\n",
        "\n",
        "**Goals achieved**:\n",
        "\n",
        "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
        "- Train a small neural network to classify images\n",
        "\n",
        "Training on multiple GPUs\n",
        "-------------------------\n",
        "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
        "please check out :doc:`data_parallel_tutorial`.\n",
        "\n",
        "Where do I go next?\n",
        "-------------------\n",
        "\n",
        "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
        "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
        "-  `Train a face generator using Generative Adversarial Networks`_\n",
        "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
        "-  `More examples`_\n",
        "-  `More tutorials`_\n",
        "-  `Discuss PyTorch on the Forums`_\n",
        "-  `Chat with other users on Slack`_\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}